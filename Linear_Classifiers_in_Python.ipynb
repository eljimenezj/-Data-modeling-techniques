{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Linear Classifiers in Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOerW45elE24WAFhn/TrFlS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eljimenezj/-Data-modeling-techniques/blob/master/Linear_Classifiers_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVZ9MWIhl4KQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Clasificadores lineales en Python\n",
        "\n",
        "En este caso vamos a estudiar unas aplicaciones de clasificación utilizando  modelos machine learning. Este libro de jupyter está basado en clases tomadas de datacamp, en la cual también utilizamos una base de datos de vinos que utilizan en varias de sus clases.\n",
        "\n",
        "Este curso hace parte del track Machine Learning Scientist with Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA__Sgx7tDNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh9tciQ9o8O7",
        "colab_type": "text"
      },
      "source": [
        "Los primeros clasificadores que vamos a estudiar son regresion logistica y maquinas de soporte vectorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8kL_n9Tlz4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "fc573301-c896-4a63-fbf6-6119e0857bb9"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "digits = datasets.load_digits()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
        "\n",
        "# Apply logistic regression and print scores\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "print(lr.score(X_train, y_train))\n",
        "print(lr.score(X_test, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.9688888888888889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7F-eeifpd-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5118f900-95c7-49ce-f58e-9eab39e43553"
      },
      "source": [
        "\n",
        "# Apply SVM and print scores\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print(svm.score(X_train, y_train))\n",
        "print(svm.score(X_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9955456570155902\n",
            "0.9888888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvgCE4v2qYfx",
        "colab_type": "text"
      },
      "source": [
        "Ahora haremos uso de probabilidades: El codigo necesita cargar los datos previamente para que funcione.\n",
        "\n",
        "Fuente de datos: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "Dateset: Este es un conjunto de datos para la clasificación de sentimientos binarios que contiene sustancialmente más datos que los conjuntos de datos de referencia anteriores. Proporcionamos un conjunto de 25,000 críticas de películas altamente polares para capacitación y 25,000 para pruebas. También hay datos adicionales sin etiquetar para su uso. Se proporcionan formatos de texto sin procesar y bolsa de palabras ya procesada. Consulte el archivo README contenido en la versión para obtener más detalles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXUhiTupl4Bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate logistic regression and train\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X,y)\n",
        "\n",
        "# Predict sentiment for a glowing review\n",
        "review1 = \"LOVED IT! This movie was amazing. Top 10 this year.\"\n",
        "review1_features = get_features(review1)\n",
        "print(\"Review:\", review1)\n",
        "print(\"Probability of positive review:\", lr.predict_proba(review1_features)[0,1])\n",
        "\n",
        "# Predict sentiment for a poor review\n",
        "review2 = \"Total junk! I'll never watch a film by that director again, no matter how good the reviews.\"\n",
        "review2_features = get_features(review2)\n",
        "print(\"Review:\", review2)\n",
        "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etFYcZl0q-ee",
        "colab_type": "text"
      },
      "source": [
        "Ahora realizaremos una visualizacion de los límites de decisión en los datos para saber si es un problema linealmente separable o no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yYpvniIsmxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "wine = load_wine()\n",
        "\n",
        "X = wine.data\n",
        "y = wine.target\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo0FIhTes2_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define the classifiers\n",
        "classifiers = [LogisticRegression(),LinearSVC(), SVC(), KNeighborsClassifier()]\n",
        "\n",
        "# Fit the classifiers\n",
        "for c in classifiers:\n",
        "    c.fit(X,y)\n",
        "\n",
        "# Grafica de funcion similiar a https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html , organizar."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}